{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4783c094-614a-4d39-8f0d-313bf0f93da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/progetto-tesi-control-lora-v3-main\n"
     ]
    }
   ],
   "source": [
    "cd ~/progetto-tesi-control-lora-v3-main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bd5b401-5f7a-469b-b15e-ba3a059bce9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.\n",
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_processes` was set to a value of `1`\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--mixed_precision` was set to a value of `'no'`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "2025-07-26 16:53:26.229430: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753548806.247213    4263 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753548806.252716    4263 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1753548806.267240    4263 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753548806.267259    4263 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753548806.267262    4263 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753548806.267264    4263 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "usage: train_sdxl.py [-h] --pretrained_model_name_or_path\n",
      "                     PRETRAINED_MODEL_NAME_OR_PATH [--revision REVISION]\n",
      "                     [--variant VARIANT] [--tokenizer_name TOKENIZER_NAME]\n",
      "                     [--tokenizer2_name TOKENIZER2_NAME]\n",
      "                     [--output_dir OUTPUT_DIR] [--cache_dir CACHE_DIR]\n",
      "                     [--seed SEED] [--resolution RESOLUTION]\n",
      "                     [--train_batch_size TRAIN_BATCH_SIZE]\n",
      "                     [--num_train_epochs NUM_TRAIN_EPOCHS]\n",
      "                     [--max_train_steps MAX_TRAIN_STEPS]\n",
      "                     [--checkpointing_steps CHECKPOINTING_STEPS]\n",
      "                     [--checkpoints_total_limit CHECKPOINTS_TOTAL_LIMIT]\n",
      "                     [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]\n",
      "                     [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]\n",
      "                     [--gradient_checkpointing]\n",
      "                     [--learning_rate LEARNING_RATE] [--scale_lr]\n",
      "                     [--lr_scheduler LR_SCHEDULER]\n",
      "                     [--lr_warmup_steps LR_WARMUP_STEPS]\n",
      "                     [--lr_num_cycles LR_NUM_CYCLES] [--lr_power LR_POWER]\n",
      "                     [--use_8bit_adam]\n",
      "                     [--dataloader_num_workers DATALOADER_NUM_WORKERS]\n",
      "                     [--adam_beta1 ADAM_BETA1] [--adam_beta2 ADAM_BETA2]\n",
      "                     [--adam_weight_decay ADAM_WEIGHT_DECAY]\n",
      "                     [--adam_epsilon ADAM_EPSILON]\n",
      "                     [--max_grad_norm MAX_GRAD_NORM] [--push_to_hub]\n",
      "                     [--hub_token HUB_TOKEN] [--hub_model_id HUB_MODEL_ID]\n",
      "                     [--logging_dir LOGGING_DIR] [--allow_tf32]\n",
      "                     [--report_to REPORT_TO]\n",
      "                     [--mixed_precision {no,fp16,bf16}]\n",
      "                     [--enable_xformers_memory_efficient_attention]\n",
      "                     [--rank RANK] [--loraplus_lr_ratio LORAPLUS_LR_RATIO]\n",
      "                     [--lora_adapter_name LORA_ADAPTER_NAME]\n",
      "                     [--init_lora_weights {gaussian,pissa,pissa_niter_1,pissa_niter_2,pissa_niter_3,pissa_niter_4,pissa_niter_5,pissa_niter_6,pissa_niter_7,pissa_niter_8,pissa_niter_9,pissa_niter_10,pissa_niter_11,pissa_niter_12,pissa_niter_13,pissa_niter_14,pissa_niter_15,pissa_niter_16}]\n",
      "                     [--half_or_full_lora {half,full,half_skip_attn,full_skip_attn}]\n",
      "                     [--extra_lora_rank_modules EXTRA_LORA_RANK_MODULES [EXTRA_LORA_RANK_MODULES ...]]\n",
      "                     [--extra_lora_ranks EXTRA_LORA_RANKS [EXTRA_LORA_RANKS ...]]\n",
      "                     [--set_grads_to_none]\n",
      "                     [--dataset_script_path DATASET_SCRIPT_PATH]\n",
      "                     [--dataset_name DATASET_NAME]\n",
      "                     [--dataset_config_name DATASET_CONFIG_NAME]\n",
      "                     [--train_data_dir TRAIN_DATA_DIR]\n",
      "                     [--image_column IMAGE_COLUMN]\n",
      "                     [--conditioning_image_column CONDITIONING_IMAGE_COLUMN]\n",
      "                     [--caption_column CAPTION_COLUMN]\n",
      "                     [--max_train_samples MAX_TRAIN_SAMPLES]\n",
      "                     [--proportion_empty_prompts PROPORTION_EMPTY_PROMPTS]\n",
      "                     [--validation_prompt VALIDATION_PROMPT [VALIDATION_PROMPT ...]]\n",
      "                     [--validation_image VALIDATION_IMAGE [VALIDATION_IMAGE ...]]\n",
      "                     [--num_validation_images NUM_VALIDATION_IMAGES]\n",
      "                     [--validation_steps VALIDATION_STEPS]\n",
      "                     [--tracker_project_name TRACKER_PROJECT_NAME]\n",
      "train_sdxl.py: error: unrecognized arguments:  \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/bin/accelerate\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/home/ubuntu/.local/lib/python3.10/site-packages/accelerate/commands/accelerate_cli.py\", line 50, in main\n",
      "    args.func(args)\n",
      "  File \"/home/ubuntu/.local/lib/python3.10/site-packages/accelerate/commands/launch.py\", line 1199, in launch_command\n",
      "    simple_launcher(args)\n",
      "  File \"/home/ubuntu/.local/lib/python3.10/site-packages/accelerate/commands/launch.py\", line 785, in simple_launcher\n",
      "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n",
      "subprocess.CalledProcessError: Command '['/usr/bin/python3', 'train_sdxl.py', '--pretrained_model_name_or_path=stabilityai/stable-diffusion-xl-base-1.0', '--image_column=file', ' ']' returned non-zero exit status 2.\n",
      "bash: line 5: --caption_column=text: command not found\n",
      "bash: line 8: --resolution=512: command not found\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'accelerate launch train_sdxl.py \\\\\\n--pretrained_model_name_or_path=\"stabilityai/stable-diffusion-xl-base-1.0\" \\\\\\n--image_column=\"file\" \\\\   \\n--caption_column=\"text\" \\\\\\n--output_dir=\"./output-xl\" \\\\\\n--train_data_dir=\"/home/ubuntu/progetto-tesi-control-lora-v3-main/glasses_data\"\\n--resolution=512 \\\\\\n--train_batch_size=4 \\\\\\n--gradient_accumulation_steps=1 \\\\\\n--max_train_steps=50000 \\\\\\n--mixed_precision=\"bf16\" \\\\\\n--enable_xformers_memory_efficient_attention \\\\\\n--lora_adapter_name=\"sdxl-control-lora-v3-canny\" \\\\\\n--learning_rate=\"1e-4\" \\\\\\n--scale_lr \\\\\\n--lr_scheduler=\"constant\" \\\\\\n--loraplus_lr_ratio=\"1.0\" \\\\\\n--extra_lora_rank_modules=\"conv_in\" \\\\\\n--extra_lora_ranks=\"64\" \\\\\\n--half_or_full_lora=\"half_skip_attn\" \\\\\\n--validation_image=\"./progetto-tesi-control-lora-v3-main/glasses_data/val/img1.png\" \\\\\\n--validation_image=\"./progetto-tesi-control-lora-v3-main/glasses_data/val/img2.png\" \\\\\\n--validation_prompt=\"Prompt val 1\" \\\\\\n--validation_prompt=\"Prompt val 2\" \\\\\\n--checkpointing_steps=5000 \\\\\\n--validation_steps=5000 \\\\\\n--resume_from_checkpoint=\"latest\" \\\\\\n'' returned non-zero exit status 127.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4018/421357964.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'accelerate launch train_sdxl.py \\\\\\n--pretrained_model_name_or_path=\"stabilityai/stable-diffusion-xl-base-1.0\" \\\\\\n--image_column=\"file\" \\\\   \\n--caption_column=\"text\" \\\\\\n--output_dir=\"./output-xl\" \\\\\\n--train_data_dir=\"/home/ubuntu/progetto-tesi-control-lora-v3-main/glasses_data\"\\n--resolution=512 \\\\\\n--train_batch_size=4 \\\\\\n--gradient_accumulation_steps=1 \\\\\\n--max_train_steps=50000 \\\\\\n--mixed_precision=\"bf16\" \\\\\\n--enable_xformers_memory_efficient_attention \\\\\\n--lora_adapter_name=\"sdxl-control-lora-v3-canny\" \\\\\\n--learning_rate=\"1e-4\" \\\\\\n--scale_lr \\\\\\n--lr_scheduler=\"constant\" \\\\\\n--loraplus_lr_ratio=\"1.0\" \\\\\\n--extra_lora_rank_modules=\"conv_in\" \\\\\\n--extra_lora_ranks=\"64\" \\\\\\n--half_or_full_lora=\"half_skip_attn\" \\\\\\n--validation_image=\"./progetto-tesi-control-lora-v3-main/glasses_data/val/img1.png\" \\\\\\n--validation_image=\"./progetto-tesi-control-lora-v3-main/glasses_data/val/img2.png\" \\\\\\n--validation_prompt=\"Prompt val 1\" \\\\\\n--validation_prompt=\"Prompt val 2\" \\\\\\n--checkpointing_steps=5000 \\\\\\n--validation_steps=5000 \\\\\\n--resume_from_checkpoint=\"latest\" \\\\\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2417\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2418\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2419\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2420\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# write a basic docstring:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-103>\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'accelerate launch train_sdxl.py \\\\\\n--pretrained_model_name_or_path=\"stabilityai/stable-diffusion-xl-base-1.0\" \\\\\\n--image_column=\"file\" \\\\   \\n--caption_column=\"text\" \\\\\\n--output_dir=\"./output-xl\" \\\\\\n--train_data_dir=\"/home/ubuntu/progetto-tesi-control-lora-v3-main/glasses_data\"\\n--resolution=512 \\\\\\n--train_batch_size=4 \\\\\\n--gradient_accumulation_steps=1 \\\\\\n--max_train_steps=50000 \\\\\\n--mixed_precision=\"bf16\" \\\\\\n--enable_xformers_memory_efficient_attention \\\\\\n--lora_adapter_name=\"sdxl-control-lora-v3-canny\" \\\\\\n--learning_rate=\"1e-4\" \\\\\\n--scale_lr \\\\\\n--lr_scheduler=\"constant\" \\\\\\n--loraplus_lr_ratio=\"1.0\" \\\\\\n--extra_lora_rank_modules=\"conv_in\" \\\\\\n--extra_lora_ranks=\"64\" \\\\\\n--half_or_full_lora=\"half_skip_attn\" \\\\\\n--validation_image=\"./progetto-tesi-control-lora-v3-main/glasses_data/val/img1.png\" \\\\\\n--validation_image=\"./progetto-tesi-control-lora-v3-main/glasses_data/val/img2.png\" \\\\\\n--validation_prompt=\"Prompt val 1\" \\\\\\n--validation_prompt=\"Prompt val 2\" \\\\\\n--checkpointing_steps=5000 \\\\\\n--validation_steps=5000 \\\\\\n--resume_from_checkpoint=\"latest\" \\\\\\n'' returned non-zero exit status 127."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "accelerate launch train_sdxl.py \\\n",
    "--pretrained_model_name_or_path=\"stabilityai/stable-diffusion-xl-base-1.0\" \\\n",
    "--image_column=\"file\" \\   \n",
    "--caption_column=\"text\" \\\n",
    "--output_dir=\"./output-xl\" \\\n",
    "--train_data_dir=\"/home/ubuntu/progetto-tesi-control-lora-v3-main/glasses_data\"\n",
    "--resolution=512 \\\n",
    "--train_batch_size=4 \\\n",
    "--gradient_accumulation_steps=1 \\\n",
    "--max_train_steps=50000 \\\n",
    "--mixed_precision=\"bf16\" \\\n",
    "--enable_xformers_memory_efficient_attention \\\n",
    "--lora_adapter_name=\"sdxl-control-lora-v3-canny\" \\\n",
    "--learning_rate=\"1e-4\" \\\n",
    "--scale_lr \\\n",
    "--lr_scheduler=\"constant\" \\\n",
    "--loraplus_lr_ratio=\"1.0\" \\\n",
    "--extra_lora_rank_modules=\"conv_in\" \\\n",
    "--extra_lora_ranks=\"64\" \\\n",
    "--half_or_full_lora=\"half_skip_attn\" \\\n",
    "--validation_image=\"./progetto-tesi-control-lora-v3-main/glasses_data/val/img1.png\" \\\n",
    "--validation_image=\"./progetto-tesi-control-lora-v3-main/glasses_data/val/img2.png\" \\\n",
    "--validation_prompt=\"Prompt val 1\" \\\n",
    "--validation_prompt=\"Prompt val 2\" \\\n",
    "--checkpointing_steps=5000 \\\n",
    "--validation_steps=5000 \\\n",
    "--resume_from_checkpoint=\"latest\" \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06508cac-0b63-4877-8d36-01c4e240c2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: numpy 2.2.6\n",
      "Uninstalling numpy-2.2.6:\n",
      "  Successfully uninstalled numpy-2.2.6\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy<1.25 in /usr/lib/python3/dist-packages (1.21.5)\n",
      "\u001b[33mWARNING: Error parsing dependencies of flatbuffers: Invalid version: '1.12.1-git20200711.33e2d80-dfsg1-0.6'\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y numpy\n",
    "!pip install \"numpy<1.25\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77029676-5dd0-4141-94c0-26551f48173d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping xformers as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Collecting xformers\n",
      "  Downloading xformers-0.0.31.post1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: numpy in /usr/lib/python3/dist-packages (from xformers) (1.21.5)\n",
      "Collecting torch==2.7.1 (from xformers)\n",
      "  Downloading torch-2.7.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from torch==2.7.1->xformers) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.local/lib/python3.10/site-packages (from torch==2.7.1->xformers) (4.14.1)\n",
      "Collecting sympy>=1.13.3 (from torch==2.7.1->xformers)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx in /usr/lib/python3/dist-packages (from torch==2.7.1->xformers) (2.4)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch==2.7.1->xformers) (3.0.3)\n",
      "Requirement already satisfied: fsspec in /usr/lib/python3/dist-packages (from torch==2.7.1->xformers) (2024.3.1)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch==2.7.1->xformers)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch==2.7.1->xformers)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch==2.7.1->xformers)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch==2.7.1->xformers)\n",
      "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch==2.7.1->xformers)\n",
      "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch==2.7.1->xformers)\n",
      "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.7.77 (from torch==2.7.1->xformers)\n",
      "  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch==2.7.1->xformers)\n",
      "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch==2.7.1->xformers)\n",
      "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch==2.7.1->xformers)\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.26.2 (from torch==2.7.1->xformers)\n",
      "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.6.77 (from torch==2.7.1->xformers)\n",
      "  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch==2.7.1->xformers)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch==2.7.1->xformers)\n",
      "  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.3.1 (from torch==2.7.1->xformers)\n",
      "  Downloading triton-3.3.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/lib/python3/dist-packages (from triton==3.3.1->torch==2.7.1->xformers) (59.6.0)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch==2.7.1->xformers)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading xformers-0.0.31.post1-cp39-abi3-manylinux_2_28_x86_64.whl (117.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.1/117.1 MB\u001b[0m \u001b[31m143.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.7.1-cp310-cp310-manylinux_2_28_x86_64.whl (821.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.2/821.2 MB\u001b[0m \u001b[31m116.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m175.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m149.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m158.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m150.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m180.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m185.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m203.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m197.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m196.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m178.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m167.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Downloading triton-3.3.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.6/155.6 MB\u001b[0m \u001b[31m188.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m143.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[33mWARNING: Error parsing dependencies of flatbuffers: Invalid version: '1.12.1-git20200711.33e2d80-dfsg1-0.6'\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: nvidia-cusparselt-cu12, mpmath, triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, xformers\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19/19\u001b[0m [xformers]/19\u001b[0m [xformers]solver-cu12]2]\n",
      "\u001b[1A\u001b[2KSuccessfully installed mpmath-1.3.0 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 sympy-1.14.0 torch-2.7.1 triton-3.3.1 xformers-0.0.31.post1\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y xformers\n",
    "!pip install xformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "096b987c-98a1-40ad-9356-12eac41df72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.\n",
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_processes` was set to a value of `1`\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--mixed_precision` was set to a value of `'no'`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "2025-07-27 14:21:24.505109: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753626084.527106    5236 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753626084.533917    5236 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1753626084.550806    5236 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753626084.550854    5236 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753626084.550869    5236 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753626084.550884    5236 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "07/27/2025 14:21:29 - INFO - __main__ - Distributed environment: NO\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda\n",
      "\n",
      "Mixed precision type: bf16\n",
      "\n",
      "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
      "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
      "{'variance_type', 'thresholding', 'clip_sample_range', 'dynamic_thresholding_ratio', 'rescale_betas_zero_snr'} was not found in config. Values will be initialized to default values.\n",
      "{'use_quant_conv', 'latents_mean', 'shift_factor', 'use_post_quant_conv', 'latents_std'} was not found in config. Values will be initialized to default values.\n",
      "07/27/2025 14:21:30 - INFO - __main__ - Converting the default unet to control-lora-v3 compatible unet\n",
      "{'dropout', 'attention_type', 'reverse_transformer_layers_per_block', 'extra_condition_names'} was not found in config. Values will be initialized to default values.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/progetto-tesi-control-lora-v3-main/train_sdxl.py\", line 1498, in <module>\n",
      "    main(args)\n",
      "  File \"/home/ubuntu/progetto-tesi-control-lora-v3-main/train_sdxl.py\", line 1232, in main\n",
      "    train_dataset = TrainDataset(args, tokenizers, accelerator)\n",
      "  File \"/home/ubuntu/progetto-tesi-control-lora-v3-main/train_sdxl.py\", line 749, in __init__\n",
      "    self.dataset = _get_data_class_from_module(\n",
      "TypeError: TrainDataset.__init__() missing 1 required positional argument: 'accelerator'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/bin/accelerate\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/home/ubuntu/.local/lib/python3.10/site-packages/accelerate/commands/accelerate_cli.py\", line 50, in main\n",
      "    args.func(args)\n",
      "  File \"/home/ubuntu/.local/lib/python3.10/site-packages/accelerate/commands/launch.py\", line 1199, in launch_command\n",
      "    simple_launcher(args)\n",
      "  File \"/home/ubuntu/.local/lib/python3.10/site-packages/accelerate/commands/launch.py\", line 785, in simple_launcher\n",
      "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n",
      "subprocess.CalledProcessError: Command '['/usr/bin/python3', 'train_sdxl.py', '--pretrained_model_name_or_path', 'stabilityai/stable-diffusion-xl-base-1.0', '--output_dir', './output-xl', '--dataset_script_path', 'exps/sd_xl_tile_pair_data.py', '--image_column', 'file', '--caption_column', 'text', '--resolution', '512', '--train_batch_size', '4', '--gradient_accumulation_steps', '1', '--max_train_steps', '50000', '--mixed_precision', 'bf16', '--enable_xformers_memory_efficient_attention', '--lora_adapter_name', 'sdxl-control-lora-v3-canny', '--learning_rate', '1e-4', '--scale_lr', '--lr_scheduler', 'constant', '--loraplus_lr_ratio', '1.0', '--extra_lora_rank_modules', 'conv_in', '--extra_lora_ranks', '64', '--half_or_full_lora', 'half_skip_attn', '--checkpointing_steps', '5000', '--validation_steps', '5000', '--resume_from_checkpoint', 'latest']' returned non-zero exit status 1.\n"
     ]
    }
   ],
   "source": [
    "!accelerate launch train_sdxl.py \\\n",
    "  --pretrained_model_name_or_path \"stabilityai/stable-diffusion-xl-base-1.0\" \\\n",
    "  --output_dir \"./output-xl\" \\\n",
    "  --dataset_script_path exps/sd_xl_tile_pair_data.py \\\n",
    "  --image_column \"file\" \\\n",
    "  --caption_column \"text\" \\\n",
    "  --resolution 512 \\\n",
    "  --train_batch_size 4 \\\n",
    "  --gradient_accumulation_steps 1 \\\n",
    "  --max_train_steps 50000 \\\n",
    "  --mixed_precision bf16 \\\n",
    "  --enable_xformers_memory_efficient_attention \\\n",
    "  --lora_adapter_name \"sdxl-control-lora-v3-canny\" \\\n",
    "  --learning_rate 1e-4 \\\n",
    "  --scale_lr \\\n",
    "  --lr_scheduler \"constant\" \\\n",
    "  --loraplus_lr_ratio 1.0 \\\n",
    "  --extra_lora_rank_modules \"conv_in\" \\\n",
    "  --extra_lora_ranks 64 \\\n",
    "  --half_or_full_lora \"half_skip_attn\" \\\n",
    "  --checkpointing_steps 5000 \\\n",
    "  --validation_steps 5000 \\\n",
    "  --resume_from_checkpoint \"latest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "27f65d5d-07bd-476c-92a1-84b6c1ad5058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.\n",
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_processes` was set to a value of `1`\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--mixed_precision` was set to a value of `'no'`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "2025-07-27 16:40:39.966029: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753634439.987827    8783 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753634439.994454    8783 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1753634440.011493    8783 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753634440.011543    8783 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753634440.011557    8783 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753634440.011572    8783 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "07/27/2025 16:40:44 - INFO - __main__ - Distributed environment: NO\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda\n",
      "\n",
      "Mixed precision type: bf16\n",
      "\n",
      "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
      "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
      "{'rescale_betas_zero_snr', 'variance_type', 'thresholding', 'clip_sample_range', 'dynamic_thresholding_ratio'} was not found in config. Values will be initialized to default values.\n",
      "{'shift_factor', 'latents_std', 'use_post_quant_conv', 'use_quant_conv', 'latents_mean'} was not found in config. Values will be initialized to default values.\n",
      "07/27/2025 16:40:45 - INFO - __main__ - Converting the default unet to control-lora-v3 compatible unet\n",
      "{'attention_type', 'dropout', 'extra_condition_names', 'reverse_transformer_layers_per_block'} was not found in config. Values will be initialized to default values.\n",
      "Map: 100%|████████████████████████| 1005/1005 [00:00<00:00, 20545.88 examples/s]\n",
      "07/27/2025 16:41:56 - INFO - __main__ - ***** Running training *****\n",
      "07/27/2025 16:41:56 - INFO - __main__ -   Num examples = 1005\n",
      "07/27/2025 16:41:56 - INFO - __main__ -   Num batches each epoch = 252\n",
      "07/27/2025 16:41:56 - INFO - __main__ -   Num Epochs = 199\n",
      "07/27/2025 16:41:56 - INFO - __main__ -   Instantaneous batch size per device = 4\n",
      "07/27/2025 16:41:56 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "07/27/2025 16:41:56 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
      "07/27/2025 16:41:56 - INFO - __main__ -   Total optimization steps = 50000\n",
      "Checkpoint 'latest' does not exist. Starting a new training run.\n",
      "Steps:   0%|                                          | 0/50000 [00:00<?, ?it/s]Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/progetto-tesi-control-lora-v3-main/train_sdxl.py\", line 1514, in <module>\n",
      "    main(args)\n",
      "  File \"/home/ubuntu/progetto-tesi-control-lora-v3-main/train_sdxl.py\", line 1373, in main\n",
      "    prompt_embeds, pooled_prompt_embeds = encode_prompt(\n",
      "  File \"/home/ubuntu/progetto-tesi-control-lora-v3-main/train_sdxl.py\", line 958, in encode_prompt\n",
      "    outputs = text_encoder(\n",
      "NameError: name 'text_encoder' is not defined. Did you mean: 'text_encoders'?\n",
      "Steps:   0%|                                          | 0/50000 [00:02<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/bin/accelerate\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/home/ubuntu/.local/lib/python3.10/site-packages/accelerate/commands/accelerate_cli.py\", line 50, in main\n",
      "    args.func(args)\n",
      "  File \"/home/ubuntu/.local/lib/python3.10/site-packages/accelerate/commands/launch.py\", line 1199, in launch_command\n",
      "    simple_launcher(args)\n",
      "  File \"/home/ubuntu/.local/lib/python3.10/site-packages/accelerate/commands/launch.py\", line 785, in simple_launcher\n",
      "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n",
      "subprocess.CalledProcessError: Command '['/usr/bin/python3', 'train_sdxl.py', '--pretrained_model_name_or_path', 'stabilityai/stable-diffusion-xl-base-1.0', '--output_dir', './output-xl', '--dataset_script_path', 'exps/sd_xl_tile_pair_data.py', '--image_column', 'image', '--caption_column', 'text', '--conditioning_image_column', 'guide', '--resolution', '512', '--train_batch_size', '4', '--gradient_accumulation_steps', '1', '--max_train_steps', '50000', '--mixed_precision', 'bf16', '--enable_xformers_memory_efficient_attention', '--lora_adapter_name', 'sdxl-control-lora-v3-canny', '--learning_rate', '1e-4', '--scale_lr', '--lr_scheduler', 'constant', '--loraplus_lr_ratio', '1.0', '--extra_lora_rank_modules', 'conv_in', '--extra_lora_ranks', '64', '--half_or_full_lora', 'half_skip_attn', '--checkpointing_steps', '5000', '--validation_steps', '5000', '--resume_from_checkpoint', 'latest']' returned non-zero exit status 1.\n"
     ]
    }
   ],
   "source": [
    "!accelerate launch train_sdxl.py \\\n",
    "  --pretrained_model_name_or_path stabilityai/stable-diffusion-xl-base-1.0 \\\n",
    "  --output_dir ./output-xl \\\n",
    "  --dataset_script_path exps/sd_xl_tile_pair_data.py \\\n",
    "  --image_column image \\\n",
    "  --caption_column text \\\n",
    "  --conditioning_image_column guide \\\n",
    "  --resolution 512 \\\n",
    "  --train_batch_size 4 \\\n",
    "  --gradient_accumulation_steps 1 \\\n",
    "  --max_train_steps 50000 \\\n",
    "  --mixed_precision bf16 \\\n",
    "  --enable_xformers_memory_efficient_attention \\\n",
    "  --lora_adapter_name sdxl-control-lora-v3-canny \\\n",
    "  --learning_rate 1e-4 \\\n",
    "  --scale_lr \\\n",
    "  --lr_scheduler constant \\\n",
    "  --loraplus_lr_ratio 1.0 \\\n",
    "  --extra_lora_rank_modules conv_in \\\n",
    "  --extra_lora_ranks 64 \\\n",
    "  --half_or_full_lora half_skip_attn \\\n",
    "  --checkpointing_steps 5000 \\\n",
    "  --validation_steps 5000 \\\n",
    "  --resume_from_checkpoint latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36201474-033a-4b5c-b51c-97a730a23c5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
